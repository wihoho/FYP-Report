\section{Literature Review}
This section introduces related work on visual events recognition. There are roughly three important aspects in video recognition. The first one is to extract features from videos. Various features have been invented and improved by researchers over decades. The second aspect is the model used to represent videos. Once features are extracted, they are still not ideal for recognition. As a result, more appropriate models are needed to compactly represent videos. Lastly, there are various classification approaches. In the rest of this section, details of the above aspects will be illustrated.\\

\noindent For feature extraction, it depends on how videos are viewed. The first one is that video could be treated a series of consecutive frames. As a result, those features in images could be adopted. The features of images could be classified into two categories: local features and global features. Local features refer to descriptions of interest points. The most widely used one is Scale Invariant Feature Transform \cite{lowe2004distinctive}, which describes interest points where the centers differ from their neighbors using Difference-of-Gaussian. Other descriptors include Histogram of oriented gradients (HOG) \cite{dalal2005histograms} and Local binary pattern (LBP) \cite{ojala2002multiresolution}. Global features refer to those which encode the image based on the overall distribution of color, texture and edges. Some popular global features include color histogram and Gabor texture \cite{manjunath1996texture}. However, if video is put onto spatial-temporal dimension, where the time dimension is also considered, there are some other features to extract. Laptev used Harris corner patch detector \cite{lindeberg1998feature} to locate spatial-temporal interest points (STIP) and adopted the concatenation of Histogram of Oriented Gradient (HOG) and Histogram of Optical Flow (HOF) as descriptor \cite{laptev2005space}. Furthermore, acoustic information is also an important part in videos. Features like MFCC \cite{baillie2003audio}, which represents the short-term power spectrum in audio signals, are also often used in video event recognition. Furthermore, given the above various features, it is also possible to combine them in order to comprehensively describe videos. \\

\noindent Once features are extracted, a common framework called as Bag of Words \cite{sivic2003video}, which treats images as ``documents'' and uses histograms to represent images using visual vocabulary, is generally employed to convert frames into histograms. Because one image counts for one histogram, the video is then converted into a stack of histograms. Beyond bag of words, Grauman et al. \cite{grauman2005pyramid} proposed {\em pyramid matching}, and Lazebnik extended this idea to spatial pyramid matching \cite{lazebnik2006beyond} which takes spatial information into consideration. Apart from BoW, Zhou et al. \cite{zhou2008sift} proposed to represent videos as Gaussian Mixture Models. Firstly, a global GMM is built on SIFT features of training data. Secondly, specialized GMMs are built for video clips based on this global GMM in Maximum a Posteriori way. Each video clip is then represented by a fixed-length vector of means of Gaussian components. \\

\noindent As for recognition methods, Support Vector Machine (SVM) \cite{boser1992training} is currently the most popular classification method in event recognition systems. One fantastic feature of SVM is that it could project samples onto higher dimensional space through kernel functions easily. To make SVM better, many researchers proposed domain adaptation methods \cite{daume2007frustratingly, yang2007cross, duan2009domain, duan2012visual}, which leverage labelled samples from other domains. Normally, these methods update the objective function and maximization function of SVM to take training samples from other domains into consideration. Furthermore, graphical models include Hidden Markov Model (HMM) and Bayesian network (BN) are also employed for recognition.  Xie et al. \cite{xie2002structure} proposed to use multiple levels of HMM to classify play and non-play segments of soccer videos. Moreover, Huang et al. \cite{huang2006semantic} proposed to use dynamic Bayesian network to perform semantic analysis on soccer videos. \\

\noindent To conclude, there are three aspects in video recognition: feature, model and classification. Various approaches on these three aspects have been proposed. Those approaches introduced in literatures have laid a solid foundation in the filed of video recognition. Because of the foundation, we can see further by standing on the shoulders of giants. In other words, this project could never be done well without researchers' efforts. 