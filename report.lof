\contentsline {figure}{\numberline {1}{\ignorespaces SIFT descriptor \cite {solem2012programming} (a) a frame with $4 \times 4$ subregions around an interest point. (b) an 8 bin histogram over the direction of gradient in one subregion. (c) all histograms in their respective subregions. (d) all 16 histograms are concatenated to form a 128 ($16 \times 8$) dimensional vector.\relax }}{15}
\contentsline {figure}{\numberline {2}{\ignorespaces Example to construct a three-level pyramid \cite {lazebnik2006beyond}. At top, images are divided at three different levels of resolution. Next, the count to each feature is calculated for each spatial bin. Finally, each histogram is weighted according to equation (2)\relax }}{18}
\contentsline {figure}{\numberline {3}{\ignorespaces A case of k nearest neighbor. Among 5 neighbors of $x_{q}$, three are negative while the other two are positive. As a result, the label of $x_{q}$ is predicted to be negative.\relax }}{19}
\contentsline {figure}{\numberline {4}{\ignorespaces Optimal hyperplane which separates a linearly separable dataset\relax }}{20}
\contentsline {figure}{\numberline {5}{\ignorespaces Image $A$ and $B$ are divided into 4 parts equally. Then each part is converted into a histogram. Thus, four histograms are stacked to represent each image.\relax }}{23}
\contentsline {figure}{\numberline {6}{\ignorespaces Matches between segments of $A$ and $B$ calculated by EMD. As we can see, the gun, human body and ground are matched properly. Therefore, distance with alignment shall be more accurate.\relax }}{24}
\contentsline {figure}{\numberline {7}{\ignorespaces $8 \times 36$ Hash Table \cite {zhao2007near}\relax }}{26}
\contentsline {figure}{\numberline {8}{\ignorespaces Near duplicate example. The colored lines in upper two images connect partial matched interest points, and the below two images are original images.\relax }}{27}
\contentsline {figure}{\numberline {9}{\ignorespaces Key frames identification example. In this cluster, there are three connected components. One frame is selected from each connected component. The resulting three frames are treated as representative frames.\relax }}{28}
\contentsline {figure}{\numberline {10}{\ignorespaces Illustration of building specialized GMMs for videos \cite {zhou2008sift}. The first step is to build a global GMM based on SIFT features of training data. The second step is to derive a specialized GMM from the global GMM for each video clip.\relax }}{32}
\contentsline {figure}{\numberline {11}{\ignorespaces Illustration of Aligned Space-Time Pyramid Matching at level one \cite {duan2012visual}. (a) Each video clip is divided into 8 sub videos. (b) Matched sub videos are painted in the same color.\relax }}{35}
\contentsline {figure}{\numberline {12}{\ignorespaces Comparison between traditional machine learning and domain adaptation. Data samples from other domains are also used as training data.\relax }}{38}
\contentsline {figure}{\numberline {13}{\ignorespaces Samples from the image data set used in experiments \cite {li2011actions}\relax }}{45}
\contentsline {figure}{\numberline {14}{\ignorespaces Chart representation of combined Table 5 and Table 6\relax }}{46}
\contentsline {figure}{\numberline {15}{\ignorespaces Chart representation of MAPs using txx, tfc, Gaussian soft\relax }}{51}
\contentsline {figure}{\numberline {16}{\ignorespaces Gaussian Mixtures Models built by different covariance types \cite {scikit-learn}.\relax }}{53}
\contentsline {figure}{\numberline {17}{\ignorespaces Chart representation of Table 16\relax }}{57}
\contentsline {figure}{\numberline {18}{\ignorespaces Snapshot of mode 1. In mode 1, the distance matrix of Youtube videos is calculated offline. The user could randomly select the training data and testing data to check the recognition performance.\relax }}{59}
\contentsline {figure}{\numberline {19}{\ignorespaces Snapshot of mode 2. In mode 2, the user could upload a new video and get the label of this video predicted by the underlying recognition system\relax }}{60}
