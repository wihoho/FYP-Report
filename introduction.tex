\section {Introduction}
Nowadays, with the development of technology, digital cameras and mobile phones with cameras are becoming more and more common. As a result, the number of videos is increasing exponentially. According to Youtube statistics, 100 hours of videos are uploaded every minute, and over 6 billion hours of videos are watched each month in Youtube. Due to such a large number of videos, it is urgent and important to develop effective and robust approach to index and retrieve videos. Also, because of the large number of videos, it is costly to rely on human power to recognize videos. Thus, one direction is to recognize videos by leveraging machine intelligence. The general way is to use a set of training videos with labels to build classifiers. Afterward, these classifiers could be used to predict labels for new coming videos. However, in order to build a robust classifier, there is a lot of work to do. \\

\noindent In this final year project, various approaches are studied and implemented to recognize videos. This project starts with image recognition because the data size of images is much smaller compared with videos. To represent images, SIFT features \cite{lowe2004distinctive} are extracted from images, the features of each image are converted into a histogram based on visual vocabulary built through clustering algorithm using spatial pyramid matching \cite{lazebnik2006beyond}. Then such representations are input into machine learning classification methods including SVM and KNN for recognition. Furthermore, to better calculate image-to-image distance, earth mover's distance (EMD) \cite{rubner2000earth} is incorporated, and the recognition accuracy demonstrates the effectiveness of EMD. Also, a method to identify representative images from a cluster of images is introduced, and this method is later on use to compress videos to remove redundant frames. This project then moves to video recognition, in which two types of representations are adopted to represent videos. The first one is the famous bag of words model, which treats each video as multiple frames, and represents each video as a stack of histograms \cite{duan2012visual} where each histogram represents a frame in that video. Moreover, in the second representation, each video is treated as a bag of SIFT features \cite{zhou2008sift}, and specialized Gaussian Mixture Models (GMM) are built on this bag to represent this video. Before building specialized GMM, a global GMM is first built on SIFT features of all training videos. Due to two different representations of videos, two different distance calculations are used. Furthermore, concept attribute \cite{liu2013video}, which models each video as a vector of scores of semantic concepts, is also studied and implemented. Based on the performance, it shows that such short vector representation still retains comparable discriminable power compared with original representations of videos. This is not the end of story. Promising domain adaptations methods \cite{duan2012visual, duan2009domain, yang2007cross, daume2007frustratingly}, which leverage labelled samples from other domains, are also researched. Feature Replication, Adaptive SVM, Domain Transfer SVM and Adaptive Multiple Kernel Learning are implemented in Python and improve the performance of recognition from the original $44.33\%$ to as high as $61.40\%$ using the metric of mean average precision. Lastly, with popular open source packages including Django and Bootstrap, a web based demo system is implemented to present the work of this project. \\

\noindent The rest of this report is organized as follows: firstly, literature review is presented followed by the section of details on image recognition. Secondly, the section of video recognition, which introduces Aligned Space-Time Pyramid Matching and Specialized Gaussian Mixture Models, is presented. Thirdly, four domain adaptations methods are talked about followed by the section of comprehensive experiments. Next, the design of web-based demo system is briefly introduced. Finally, this report ends with the section of conclusion. 